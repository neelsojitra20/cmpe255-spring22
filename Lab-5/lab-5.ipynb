{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\n#!pip install --upgrade scikit-learn==0.20.3\n!pip install pydotplus\n\nfrom matplotlib import pyplot\n\n# Some functions to plot our points and draw the lines\ndef plot_points(features, labels, fix_margins=True):\n    X = np.array(features)\n    y = np.array(labels)\n    spam = X[np.argwhere(y==1)]\n    ham = X[np.argwhere(y==0)]\n    if fix_margins:\n        pyplot.xlim(0, 11)\n        pyplot.ylim(0, 11)\n    pyplot.scatter([s[0][0] for s in spam],\n                [s[0][1] for s in spam],\n                s = 100,\n                color = 'cyan',\n                edgecolor = 'k',\n                marker = '^')\n    pyplot.scatter([s[0][0] for s in ham],\n                [s[0][1] for s in ham],\n                s = 100,\n                color = 'red',\n                edgecolor = 'k',\n                marker = 's')\n    pyplot.xlabel('Lottery')\n    pyplot.ylabel('Sale')\n    pyplot.legend(['Spam','Ham'])\n\ndef plot_model(X, y, model, fix_margins=True):\n    X = np.array(X)\n    y = np.array(y)\n    plot_points(X, y)\n    plot_step = 0.01\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    if fix_margins:\n        x_min=0\n        y_min=0\n        x_max=12\n        y_max=12\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n                         np.arange(y_min, y_max, plot_step))\n    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    pyplot.contourf(xx, yy, Z, colors=['red', 'blue'], alpha=0.2, levels=range(-1,2))\n    pyplot.contour(xx, yy, Z,colors = 'k',linewidths = 3)\n    pyplot.show()\n\ndef display_tree(dt):\n    from sklearn.externals.six import StringIO  \n    from IPython.display import Image  \n    from sklearn.tree import export_graphviz\n    import pydotplus\n    dot_data = StringIO()\n    export_graphviz(dt, out_file=dot_data,  \n                    filled=True, rounded=True,\n                    special_characters=True)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n    return Image(graph.create_png())\n    \ndef plot_trees(model):\n    estimators = gradient_boosting_model.estimators_\n    for i in range(len(estimators)):\n        tree.plot_tree(estimators[i][0])\n        pyplot.show()\n        #plot_model(new_X, new_y, estimators[i][0])\n        \ndef plot_regressor(model, features, labels):\n    x = np.linspace(0,85,1000)\n    pyplot.scatter(features, labels)\n    pyplot.plot(x, model.predict(x.reshape([-1,1])))\n    pyplot.xlabel(\"Age\")\n    pyplot.ylabel(\"Days per week\")\n    pyplot.show()\n    \nfrom matplotlib import pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\nnp.random.seed(0)\n\n# Spam Email dataset\nemails = np.array([\n    [7,8,1],\n    [3,2,0],\n    [8,4,1],\n    [2,6,0],\n    [6,5,1],\n    [9,6,1],\n    [8,5,0],\n    [7,1,0],\n    [1,9,1],\n    [4,7,0],\n    [1,3,0],\n    [3,10,1],\n    [2,2,1],\n    [9,3,0],\n    [5,3,0],\n    [10,1,0],\n    [5,9,1],\n    [10,8,1],\n])\nspam_dataset = pd.DataFrame(data=emails, columns=[\"Lottery\", \"Sale\", \"Spam\"])\nspam_dataset\n        \nfeatures = spam_dataset[['Lottery', 'Sale']]\nlabels = spam_dataset['Spam']\nplot_points(features, labels)\n\n# Decision Tree\ndecision_tree_classifier = DecisionTreeClassifier(random_state=42)\ndecision_tree_classifier.fit(features, labels)\ndecision_tree_classifier.score(features, labels)\n\n# Draw decision tree\ndisplay_tree(decision_tree_classifier)\n# Decision tree as map\nplot_model(features, labels, decision_tree_classifier)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T00:04:32.823482Z","iopub.execute_input":"2022-04-26T00:04:32.824291Z","iopub.status.idle":"2022-04-26T00:04:48.638879Z","shell.execute_reply.started":"2022-04-26T00:04:32.824245Z","shell.execute_reply":"2022-04-26T00:04:48.638145Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Training a Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest_classifier = RandomForestClassifier(random_state=0, n_estimators=5, max_depth=1)\nrandom_forest_classifier.fit(features, labels)\nrandom_forest_classifier.score(features, labels)\n\n# plot\nplot_model(features, labels, random_forest_classifier)\n\nplot_points(features, labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T00:04:48.640262Z","iopub.execute_input":"2022-04-26T00:04:48.640455Z","iopub.status.idle":"2022-04-26T00:04:49.978083Z","shell.execute_reply.started":"2022-04-26T00:04:48.640428Z","shell.execute_reply":"2022-04-26T00:04:49.977618Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nclf = AdaBoostClassifier(n_estimators=100, random_state=0)\nclf.fit(features, labels)\nclf.score(features, labels)\n\n\nplot_model(features, labels, clf)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T00:04:49.979127Z","iopub.execute_input":"2022-04-26T00:04:49.979812Z","iopub.status.idle":"2022-04-26T00:05:02.273669Z","shell.execute_reply.started":"2022-04-26T00:04:49.979775Z","shell.execute_reply":"2022-04-26T00:05:02.273260Z"},"trusted":true},"execution_count":4,"outputs":[]}]}